The topic of study has been widely studied by researchers in industries that concerns about improvements of web performances. But even though that is the case, not much available data is applicable for the characteristic of this study, which is focused specifically on the quantifiable metrics of image performances. This is the reason why a new experiment is needed to be conducted, producing a specific dataset to be gathered and analysed for this study.
        2.1 Research design
The experiment and the dataset of this study has served the purpose of answering the questions of research. To achieve such goal, the experiment has gathered a combination of quantitative and qualitative dataset. The experiment was being held online, and has been limited desktop only. The online aspect of the experiment recreate the environment of real life browsing better than if it's being held on site. But because of this online aspect, the participants would pay more attention if they do the experiment on desktop platforms, instead of going through the experiment quickly on their mobile phones.
Looking further in, the test had two main sections that all participants had gone through. The experiment started with the introduction phase, where the participants are informed about what the study is about, and what to do in during the experiment, they were leaded into the first phase. This is where a landing page of a SaaS product was presented to them. 
The participants were instructed to browse the page with the goal of understanding what the product is about. The reason for this instruction is that with a task to perform, participants are more likely to pay more attention to the experience. In contrast, the subjects would not pay much attention if they’re freely browsing without a task to perform. This conclusion was reached after multiple pilot tests that yielded results of less time on page, indicating the low attention that the participants have given into the experience.
Then the subjects answered a series of questions related to the experience that they’ve just went through, before continuing to the next section of the experience. In the followed section, the same landing page will be showed to the participants, and their only task to complete remains the same: pay attention to what the product is about. After the second section, the participants will be asked with the same series of question as they’ve answered in the first section, which when completed, concludes the experiment. 

((( user journey diagram here )))

The difference between the two versions of the same landing page lies on the performance of their images. Although the two versions of the landing page have the same exact texts and images, the images of the first version are noticeably slow but have high quality, whereas the ones in the second version load as fast as subject’s internet bandwidth allows, but their quality is scaled down to where texts in the images are hard to read.
Because the two versions of the landing page have the same content, and the test subjects have the same task to perform in both phases, the first phase is predicted to provide more reliable data points. This is because this first version is their first impression of the landing page, and the participants will have more natural behaviour. This mode of behaviour can be compared to users in real life behave when entering a landing page for the first time. When this first version of the landing page is viewed, the participants were likely to be familiarized with the products and the descriptions of it, so their second time viewing the page will be faster because they can already expect what the page is about. This first-impression aspect is the reason why the experiment must also cycle between the two versions of the landing page, alternating the version being shown first between participants. As the result of this additional step, the answers to the research question can become clearer.
To further achieve the neutral response of the participants, the product introduced in the experiment needs to be a more neutral one. Since participants have different views towards different products, due to the differences in their needs at the time of testing, results can be too varied if the type of product is too emotionally attached. By selecting a more neutral product to put into the experiment, the images and texts that describes it on the landing page also are also needed to be neutral. Pictures should not include faces in them, and texts should not include languages that are too emotionally stimulating. When put into effect, the neutral choice of product, images, and texts will elevate the dramatic performance of the images, in order catch participants' attention, and create a more memorable perspective of the images for a more on-topic result.

    Technology choices
Since the experiment and survey is built from scratch, there are some technological decisions that have been made during the development phase. This experiment's goal is try to understand user behaviours to web performance, by deliberately slowing down the images on the webpages. Therefore the faster the speed of the webpages, the less diluted the results will be.

There are many techniques that can be applied to achieve a high performance website, but would take decent time to develop. To reduce the complexity of the project to give way for the analyzation and report, one method of optimization is utilized, which is limit the usage of code libraries and frameworks. The landing pages and survey was built with pure HTML5 and CSS3. There are many front-end libraries and frameworks that accelerate and ease the development processes, but have the tendency to underperform pure HTML and CSS, so these two remain as the choices for developing the front-end of the test. The back-end of the experiment was built with the Go programming language and data saved onto SQLite3. Go and its libraries' speed are one of the top amongst other popular general-purpose programming languages, and SQLite is a lightweight, flexible relational database, hence the decision of adopting them into the development of the experiment.

Another reason for adopting these technologies is their ease to be studied and replicated. Since these technologies are the base layer of popular libraries and frameworks built on top of them, documentations and guides are more readily available. This will not hinder further studies if they want to adjust a part of this already built experiment, or pull them off of creating a entire new experiment and use this one as an example.

        The Landing Page
In the User Experience test, two versions of the same landing page was presented to the study participants. They are identical in their content, but different in their image's load speed and sharpness. The landing page in the study is for a non-existing SaaS company, providing a software that helps its users make better schedulings for their projects, named Planito. 
The landing page have five main sections, lies between the header and footer. The graphics, layouts, and the poportions between texts and images in these sections replicates common SaaS landing pages designs. Located at the top of the landing page is the hero section, designed to give a introduction and give a promise what information the user will get out of browsing this landing page. The following section is the list of Planito's features and its list of benefits. After the viewers attention have been captivated, next comes a series of Planito's benefits explained in further details. These feature showcasing sections consist of images of the product on one side, and its description on another side. The main goal of these sections is to give the viewer a closer view into what the product can do, and if the user becomes interested one or more use cases, they would proceeds to click on the "call to actions" buttons or links that leads them into either more details information of the product's feature or get the products. The final section is laid after these series of product features. In this final section, a final "call to action" is presented as the final attemp to convert the viewer into a user.

((( image of the plain landing page )))

The three sections that consist of images are meant to captivate the viewers attention. Although it is the descriptive texts inside or next to the images are the actual thing that give the viewers the information that they needed to evaluate the values of the product, the viewers did not do so before they have finished scanning for what to read in the first place. The scanning process is accelerated with the images, because it is with the size, shape and colors of the images that allow the viewers to quickly evaluate the main purpose of each sections. The pictures on the landing page are meant to both presentate how the product looks like at work, and to help the viewer search for the information that they are looking for. If they want to know what can the product help them with, they can look at the list of benefits faster by looking at the combination of image and title that this section has. On the other hand, if the viewer want to know what exactly the product can do, they can look at the section with that contains one big picture of the product to understand that this is about exactly one feature of the product. 
The landing page also have been tailored with wordings and images that are not too emotionally engaging, leave way for the emotions of the participants to focus onto the images, which is the only in inefficient part of the webpage by design purpose of the test.

        2.2 Sampling
In the time of writing, browsing websites is an integrated activity in most of our lives, no matter what the age is. But each age group have tendencies to behave differently than one another when it comes to browsing websites. 
Due to the limited size and resource of this research, its study group is narrowed to a specific demographic group, consist of university students with ages ranging from 20 to 27 years old. This demographic group, like any other demographic group, have distinct internet browsing habits that can be lightly generalized. Because they have adapted to the internet for a large part of their life, they know what to expect from a website such as the landing page in the experiment. Their mode of browsing landing pages is mostly skimming, and slowing down only when something on the page catches their interest. Their tolerance level of slow loading or low quality websites are varied from person to person like any other demographic groups, but overall they lean towards the lower end. Products that are not in interest, lengthy description texts, low quality visuals are skipped because of this low tolerance level. This is also the reason why instructing a task for the participants to do can also help extracting more information that align to the natural behaviour outside of the study.

    3 Data
        3.1 Data Collection
There are two distinct section that data are being collected from the experiment, at the landing pages that the participants view and the survey they answered. 
When the subjects enters either one of the two landing pages, their mouse activities are starting to be recorded, including their mouse hovering positions and their click counts. To optimize the speed of the experiment and to make the dataset easier to handle, each elements of the website are assigned with a counter that increases when the mouse is hovered on them and when they are clicked. The alternative to this design is to record these hovering time and click count based on mouse positions, then calculate what element lies on those positions on the server. This alternative option is less optimal because the data weight of each participants increases on  time in Big O, whereas the data weight of the chosen option stay constant no matter how long the subjects stay on the page.
After the participant finishes viewing each version of the landing page, a series of questions about the landing page they have just viewed are presented to them. The questions asked the participants for their overall experience of images on the landing page they have just viewed, both on their sharpness and load speed. In the middle of the series of question, the participant is asked for why they spend most of their time on the page hovering over a specific element, which can help confirming the hypothesis in the analysis phase. Overall, the two surveying sections of the experiment are meant to clarify their behaviours and better understand their feelings towards each version of the landing page.
        3.2 Data Presentation
After being cleansed and organized, there are ___ remaining entries for each of the version of the landing page. The dataset is consist two main sections, first being the interaction data measured when the particicpants are browsing the landing pages. This includes the their mouse hovering positions and click counts on each elements. The second section of the dataset are the responses from the survey, both numeric and free form texts.

The actual dataset consist of a total of ___ elements being measured for clicks and ___ for hover time. The analysis makes use of the average, highest and lowest hovering time entries. 

(((image of stats of hovering data))))

Beside from hovering times, the study will also make use of the to total time on page (which named "top" in the dataset). The same entries as the hovering time are used in this a criteria: average, highest and lowest. 

(((image of stats of time on page data))))

In each of those entries, there are ___ elements have been counted for clicks, and ___ sections hovering time have been measured. Using the selection of these data points will help reveal the answers for the research question.

(((Fill the blanks)))
(((image of summary of surveying data)))

The surveying parts of the experiments are there for both contribute to the analyzation of the interaction dataset and to support the claims that arrives from such analyzation. Because these questions are asked right after the landing pages are being viewed, participants can evaluate the experience they have just been through and give accurate answers.

    4 Analysis
With the collected dataset, the study can apply some analysis onto them to understand subjects' behaviours, and through that, to answer the research question. With the research question as the aim to achieve, this analysis will also be split into two sections. Successfully answering the first question with partly provide a path to answer the second one, as the dataset have been understood more clearly.
But before jumping into the specific analysis of the dataset, there is a need to zone in the focus area of the it. The overall impact of image performance can be measured by combining the data of both the blurry version and slow loading version of the landing page. 
After that, to determine the impact of image performance on participants views of the landing pages, the first aspect that need to be identified is how what the subject is paying attention to when they browse. Assuming that the more time the subject spent hovering over an element, the more attention they have put onto that element. On the other hand, the less hover time the element has, the less attention it has been put on by the participant. 

When looking at the average hover time of all entries, we can see the largest time combined are spent in viewing the hero section of the website. This is expected, as it is the first section that shows up to the participants when they enter the site. Combined with the description that promises and give information on what the site is about, the hero title has been able to capture the users' attention like how it's supposed to be.
To understand which elements or sections of the landing page, further than the hero section, we can follow the users' journey and look at the lower sections as they have also scrolled down. The two most viewed section beside from the hero section is the list of features that consist three big images right below the hero section, and the big second feature showcasing that includes the image of the feature and a paragraph of description on the right of it, with the title of "Adapt to changes".
These two sections have almost equal hovering time. The benefit list has approximately 3.6 seconds of hovering time, and the feature showcasing has a slightly larger view time being approximately 4.1 seconds. The five hundreds milliseconds might seem little at first, but this is actually a notable gap because not only this is the average of 20 subjects, but also the browsing speed and behaviours can varies among participants. The differences can be further demonstrated in the later points.
What similar about these two sections is not only their seemingly similar load time, but also their image size. Each images of the benefit list is smaller than the one at the feature showcase, but when combined together, they create a whole section consist of only images. That whole section full of images is larger than the one image at the feature showcase section. The two most notably viewed sections being the ones with images of the larger size. This can translate into that subjects paid more attention to sections consisting of larger, more detailed images than the sections that have little or no images at all. 
Broadening the range from the two most viewed elements that separate themselves from the others, the three elements that have lower hovering time also share this trait. The three other feature showcasing session with their hovering time of 3.2, 1.93 and 1.87 seconds. These three sections have the same characteristics as the most hovered element at 4.1 seconds, but because of their position on the page, their hovering time are different from each other. Sharpness and load speed when combined with positioning can produce this difference in hovering time. 
In average, participants pay more attention to sections that have impressive and detailed images than the ones without. To see more precisely how image effect each individual when they browse landing pages, further examinations are needed in one specific participant entry. First the highest hovering time entry will be viewed, following by the lowest hovering time entry.
The proportions of that the participant with the highest time on page is almost the same as the measurements that have just been analysed. The benefit list and the "Adapt to changes" feature showcasing remains to be the two longest viewed sections. In this entry, the attentive participant spent a significant time viewing the section with the big image, with the total of 31 seconds. This amount of time is almost equal to the hovering time of the hero section, which was 38 seconds, and triple the second highest element of 10 seconds.  

When looking further into distribution of time this subject has spent for this section, more can be realized. The image of this section is being paid more attention than the descriptive texts that lies next to it. This entry's first version of the landing page shown to this participant is the one with low quality images. Because of this, this participant's long hovering behaviour on the image might have happen due to him or her trying to read the blurry text on the images. 
This can be confirmed by the answered they gave to the questions on the survey about this matter. On the question asking for the image's quality, the participants answered with the lowest option of "blurry". But even though the images sharpness was poor, the participants answered that those images still made them stopped scrolling and read around those blurry images, and the texts next to it, and it hadn't made them skipped the blurry sections to browse other sections. But after giving all of this attentions, the participant answered that the blurry images was not enough to convince them to know more about the product outside of the landing page, and that they do not want to try the product. Finally the concluded the survey by claim that it was more appealing for him or her to scan the website with the help of images, but the bad image quality did not support them to understand the product, which has formed a bad impression of the company and the product that was presented.
The main learning that these answers provided is that images can have a notable impact on the judgement of an attentive and interested viewer, but capturing their attention is not enough to convert the viewer into an further engagements. Poor quality images overall can turn away an interested viewer, and create a accorded poor brand in the viewer's mind.

The browsing pattern of this participant was rapid and move quickly throughout many most parts of the page, trying to find what was interactive. This is the captured hovering time of the participant with the least time spent on page, with a total of only 9 seconds. This behaviour pattern is the opposite of the previous entry, where they stay calm and read or wait the images patiently. 

Although when scrolling to look for information at a fast rate, the longest viewed time on the page was on the first feature showcase. This section is the first of the section that have a big image as one of its elements. This big image has captivated the attention of the fast-browsing subject, with held them down onto one section for 4.5 seconds, which is half of the total time spent on page. Compare that to other elements that the subject just flicks through for less than a second, this first feature section has done a decent job of holding extended attention. This understanding is a contribution on clarifying the importance of images on landing page, and its effect on different user personas. People with different browsing habits can have different perspectives on images, but as in the majority of cases, images are at the core of users' experiences.

In the dataset, there are 2 participants that have not fully completed the experiment. One of those entry has completed the first version of the landing page, but have left before viewing the second version of the page. This means that they have viewed the first version of the landing page, which is the slow loading version in this entry, then left at the interim in between the two versions. The second participant that have not completed the full experiment has viewed the second version of the landing page, but have left every survey answer for the second phase empty.

These two entries' time on page was 15 and 44 seconds respectively, which are not the lowest time on page out of all the entries. They have the same aspect lies on having first feature showcasing section as the most viewed section, and the remainding time on page is scattered around most elements of landing page. This can mean that both participant have browse the page quickly, before their attention are captured by section with the big image. This can add to the result that the rest of the dataset have been ariving at, that images have effect on the experience of the viewers viewing a landing page, even to the point that they can't stand and leave the whole experience earlier than expected.
